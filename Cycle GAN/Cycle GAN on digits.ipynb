{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Projet_DL_Cvarennes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkDzYU4fEYjd"
      },
      "source": [
        "from mlxtend.data import loadlocal_mnist\n",
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Subset,TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U48rzJXcBkF"
      },
      "source": [
        "### Fonctions utiles afin de simplifer l'implémentation\n",
        "en effet, la plupart des oppérations sont similaires, à l'utilisation d'un BatchNorm près"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHD9dp3MJpxP"
      },
      "source": [
        "def dconv(in_, out, kernel, stride=2, padding=1, batch_norm=True):\n",
        "    l = []\n",
        "    l.append(nn.ConvTranspose2d(in_, out, kernel, stride, padding, bias=False))\n",
        "    if batch_norm:\n",
        "        l.append(nn.BatchNorm2d(out))\n",
        "    return nn.Sequential(*l)\n",
        "\n",
        "def conv(in_, out, kernel, stride=2, padding=1, batch_norm=True):\n",
        "    l = []\n",
        "    l.append(nn.Conv2d(in_, out, kernel, stride, padding, bias=False))\n",
        "    if batch_norm:\n",
        "        l.append(nn.BatchNorm2d(out))\n",
        "    return nn.Sequential(*l)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MXsBejVcBkL"
      },
      "source": [
        "### Réseaux de neurones pour les générateurs et discriminateurs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvOFobNHEYj4"
      },
      "source": [
        "class DMNIST(nn.Module):\n",
        "    \"\"\"MNIST discriminateur\"\"\"\n",
        "    def __init__(self, conv_dim=28, use_labels=False):\n",
        "        super(DMNIST, self).__init__()\n",
        "        self.conv1 = conv(1, 28, kernel=5, stride=2, padding=0, batch_norm=False)\n",
        "        self.conv2 = conv(28, 56,kernel=5, stride=2, padding=1)\n",
        "        self.conv3 = conv(56, 112, kernel=2, stride=2, padding=0)\n",
        "        self.conv4 = conv(112, 1, kernel=2, stride=2, padding=0, batch_norm=False)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.conv1(x))    \n",
        "        out = F.relu(self.conv2(out))  \n",
        "        out = F.relu(self.conv3(out))\n",
        "        out = self.conv4(out) \n",
        "        return out.squeeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZU_2FkYEYj9"
      },
      "source": [
        "class DUSPS(nn.Module):\n",
        "    \"\"\"USPS discriminateur\"\"\"\n",
        "    def __init__(self):\n",
        "        super(DUSPS, self).__init__()\n",
        "        self.conv1 = conv(1,  16, kernel=4, stride=2, padding=1, batch_norm=False)\n",
        "        self.conv2 = conv(16, 32, kernel=4, stride=2, padding=1)\n",
        "        self.conv3 = conv(32, 64,kernel=2, stride=2, padding=0)\n",
        "        self.conv4 = conv(64, 1, kernel=2, stride=2, padding=0, batch_norm=False)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.conv1(x))\n",
        "        out = F.relu(self.conv2(out))\n",
        "        out = F.relu(self.conv3(out)) \n",
        "        out = self.conv4(out)\n",
        "        return out.squeeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIWRz4qdEYkK"
      },
      "source": [
        "class GMNISTUSPS(nn.Module):\n",
        "    \"\"\"MNIST --- > USPS\"\"\"\n",
        "    def __init__(self, conv_dim=16):\n",
        "        super(GMNISTUSPS, self).__init__()\n",
        "\n",
        "        # encoding\n",
        "        self.conv1 = conv(1, 8, 4, 1, 0)\n",
        "        self.conv2 = conv(8, 16, 5, 2, 0)\n",
        "        self.conv3 = conv(16, 32, 5, 2, 0, False)        \n",
        "        \n",
        "        # resnet\n",
        "        self.conv4 = conv(32, 32, 3, 1, 1)\n",
        "        self.conv5 = conv(32, 32, 3, 1, 1)\n",
        "\n",
        "        \n",
        "        # decoding\n",
        "        self.dconv1 = dconv(32, 16, 5, 2,0)\n",
        "        self.dconv2 = dconv(16, 8, 4,1,0)\n",
        "        self.dconv3 = dconv(8, 1, 3, 1, 0, False)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.conv1(x)) \n",
        "        out = F.relu(self.conv2(out)) \n",
        "        out = self.conv3(out)\n",
        "\n",
        "        out = self.conv4(out)\n",
        "        out = F.relu(self.conv5(out))\n",
        "\n",
        "        out = F.relu(self.dconv1(out)) \n",
        "        out = F.relu(self.dconv2(out))\n",
        "        out = self.dconv3(out)\n",
        "        return torch.tanh(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrDr_xpJEYkD"
      },
      "source": [
        "class GUSPSMNIST(nn.Module):\n",
        "    \"\"\"USPS --- > MNIST\"\"\"\n",
        "    def __init__(self, conv_dim=16):\n",
        "        super(GUSPSMNIST, self).__init__()\n",
        "        # encoding\n",
        "        self.conv1 = conv(1, 8, 3, 1, 0)\n",
        "        self.conv2 = conv(8, 16, 4, 1,0)\n",
        "        self.conv3 = conv(16, 32, 5, 2, 0 ,False)\n",
        "        \n",
        "        \n",
        "        # resnet\n",
        "        self.conv4 = conv(32, 32, 3,1, 1)\n",
        "        self.conv5 = conv(32, 32, 3,1, 1)\n",
        "\n",
        "        \n",
        "        # decoding\n",
        "        self.dconv1 = dconv(32, 16, 5, 2, 0)\n",
        "        self.dconv2 = dconv(16, 8, 5, 2, 0)\n",
        "        self.dconv3 = dconv(8, 1, 4, 1, 0, batch_norm=False)\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.conv1(x))\n",
        "        out = F.relu(self.conv2(out) )\n",
        "        out = self.conv3(out)\n",
        "\n",
        "        out = self.conv4(out)\n",
        "        out = F.relu(self.conv5(out))\n",
        "\n",
        "        out = F.relu(self.dconv1(out))\n",
        "        out = F.relu(self.dconv2(out))\n",
        "        out = torch.tanh(self.dconv3(out))\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXOvwk_scBkb"
      },
      "source": [
        "### Récupération et mise en forme des données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH4hydYSEYjo"
      },
      "source": [
        "X, y = loadlocal_mnist(\n",
        "        images_path='./MNIST_train_im', \n",
        "        labels_path='./MNIST_train_label')\n",
        "X = X/254"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAUY_hoOEYjx"
      },
      "source": [
        "import h5py\n",
        "with h5py.File(\"./usps.h5\", 'r') as hf:\n",
        "        train = hf.get('train')\n",
        "        X_tr = train.get('data')[:]\n",
        "        y_tr = train.get('target')[:]\n",
        "        test = hf.get('test')\n",
        "        X_te = test.get('data')[:]\n",
        "        y_te = test.get('target')[:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysM2lSFMEYkT"
      },
      "source": [
        "x = np.expand_dims(X.reshape(60000,28,28), 1)\n",
        "tensor_x_1 = torch.from_numpy(x.astype(\"float32\")) # transform to torch tensor\n",
        "tensor_y_1 = torch.from_numpy(y.astype(\"float32\"))\n",
        "tensor_x_2 = torch.from_numpy(X_tr.reshape(7291,1,16,16).astype(\"float32\"))\n",
        "tensor_y_2 = torch.from_numpy(y_tr.astype(\"float32\"))\n",
        "my_dataset_1 = TensorDataset(tensor_x_1,tensor_y_1)# create your datset\n",
        "my_dataset_2 = TensorDataset(tensor_x_2,tensor_y_2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8N-yCOPEYkg"
      },
      "source": [
        "class_inds_1 = [torch.where(my_dataset_1.tensors[1] == i)[0]\n",
        "              for i in range(10)]\n",
        "class_inds_2 = [torch.where(my_dataset_2.tensors[1] == i)[0]\n",
        "              for i in range(10)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtCvWohAEYkn"
      },
      "source": [
        "dataloaders_1 = [\n",
        "    DataLoader(\n",
        "        dataset=Subset(my_dataset_1, class_inds_1[i]),\n",
        "        batch_size=64,\n",
        "        shuffle=True,\n",
        "        drop_last=False)\n",
        "    for i in range(10)]\n",
        "\n",
        "dataloaders_2 = [\n",
        "    DataLoader(\n",
        "        dataset=Subset(my_dataset_2, class_inds_2[i]),\n",
        "        batch_size=64,\n",
        "        shuffle=True,\n",
        "        drop_last=False)\n",
        "    for i in range(10)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eajsXeNOcBku"
      },
      "source": [
        "### Procédure d'entrainement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVSxUxD3EYlG"
      },
      "source": [
        "def train(usps_loader, mnist_loader):\n",
        "    lambda_ = 0.0002\n",
        "\n",
        "    G_params = list(GMU.parameters()) + list(GUM.parameters())\n",
        "    D_params = list(DM.parameters()) + list(DU.parameters())\n",
        "\n",
        "    G_optimizer = optim.Adam(G_params, lambda_)\n",
        "\n",
        "    D_optimizer = optim.Adam(D_params, lambda_)\n",
        "\n",
        "\n",
        "    usps_iter = iter(usps_loader)\n",
        "    mnist_iter = iter(mnist_loader)\n",
        "    iter_per_epoch = min(len(usps_iter), len(mnist_iter))\n",
        "\n",
        "    fixusps = Variable(usps_iter.next()[0].cuda())\n",
        "    fixmnist = Variable(mnist_iter.next()[0].cuda())\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for step in range((epochs+1) *iter_per_epoch ):\n",
        "        if (step+1) % iter_per_epoch == 0:\n",
        "            if (step+1) / iter_per_epoch -2 > epochs/2:\n",
        "                lambda_ = lambda_ - 0.0002 / (epochs/2)\n",
        "                G_params = list(GMU.parameters()) + list(GUM.parameters())\n",
        "                D_params = list(DM.parameters()) + list(DU.parameters())\n",
        "\n",
        "                G_optimizer = optim.Adam(G_params, lambda_)\n",
        "                D_optimizer = optim.Adam(D_params, lambda_)\n",
        "        mnist_iter = iter(mnist_loader)\n",
        "        usps_iter = iter(usps_loader)\n",
        "\n",
        "        # load svhn and mnist dataset\n",
        "        usps, s_labels = usps_iter.next() \n",
        "        usps = Variable(usps.cuda())\n",
        "        s_labels = Variable(s_labels.cuda()).long().squeeze()\n",
        "        mnist, m_labels = mnist_iter.next() \n",
        "        mnist = Variable(mnist.cuda())\n",
        "        m_labels = Variable(m_labels.cuda())\n",
        "\n",
        "\n",
        "        #Entrainement Discriminateurs#\n",
        "\n",
        "        #REAL#\n",
        "\n",
        "        out = DM(mnist)\n",
        "\n",
        "        DM_loss = torch.mean((out-1)**2)\n",
        "\n",
        "        out = DU(usps)\n",
        "\n",
        "        DU_loss = torch.mean((out-1)**2)\n",
        "\n",
        "\n",
        "\n",
        "        D_real_loss = DM_loss + DU_loss\n",
        "        D_real_loss.backward()\n",
        "        D_optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "        #FAKE#\n",
        "\n",
        "        D_optimizer.zero_grad()\n",
        "        G_optimizer.zero_grad()\n",
        "\n",
        "        fake_usps = GMU(mnist)\n",
        "\n",
        "        out = DU(fake_usps).\n",
        "        DU_loss = torch.mean((out)**2)\n",
        "\n",
        "        f_mnist = GUM(usps)\n",
        "        out = DM(f_mnist)\n",
        "\n",
        "        DM_loss = torch.mean((out)**2)\n",
        "\n",
        "        D_fake_loss = DU_loss + DM_loss\n",
        "        D_fake_loss.backward()\n",
        "        D_optimizer.step()\n",
        "\n",
        "        #Entrainement des Générateurs#\n",
        "        # M --- > U --- > M\n",
        "\n",
        "        D_optimizer.zero_grad()\n",
        "        G_optimizer.zero_grad()\n",
        "\n",
        "        f_usps = GMU(mnist)\n",
        "        out = DU(f_usps)\n",
        "        reconst_mnist = GUM(f_usps)\n",
        "\n",
        "        G_loss = torch.mean((out-1)**2) \n",
        "\n",
        "        cycle_loss = 0\n",
        "        for e in (mnist - reconst_mnist):\n",
        "            cycle_loss += torch.norm(e, p=1)\n",
        "        G_loss += 0.1*cycle_loss/64\n",
        "\n",
        "        G_loss.backward()\n",
        "        G_optimizer.step()\n",
        "        D_optimizer.zero_grad()\n",
        "        G_optimizer.zero_grad()\n",
        "\n",
        "\n",
        "        # U --- > M --- > U\n",
        "        f_mnist = GUM(usps)\n",
        "        out = DM(f_mnist)\n",
        "        reconst_usps = GMU(f_mnist)\n",
        "\n",
        "        G_loss = torch.mean((out-1)**2) \n",
        "\n",
        "        cycle_loss = 0\n",
        "        for e in (usps - reconst_usps):\n",
        "            cycle_loss += torch.norm(e, p=1)\n",
        "\n",
        "        G_loss += (0.1)*cycle_loss/64\n",
        "\n",
        "\n",
        "        G_loss.backward()\n",
        "        G_optimizer.step()\n",
        "        D_optimizer.zero_grad()\n",
        "        G_optimizer.zero_grad()\n",
        "\n",
        "        #infos affichées\n",
        "        if (step+1) % 500 == 0:\n",
        "\n",
        "            print('step {} on {}, real loss: {} , fake loss: {} ,  Gen loss: {}'.format(\n",
        "              step+1 , epochs*iter_per_epoch, D_real_loss.data.item(), D_fake_loss.data.item(), G_loss.data.item()\n",
        "              ))\n",
        "            print(\"lambda = {}\".format(lambda_))\n",
        "            print(\"total time: {}\".format(time.time() - begin))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzgXGpahcBky"
      },
      "source": [
        "### entrainement pour chaque domaines (chiffres de 0 à 9)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdNPhc8mEYk3",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "47589e7c-52ed-4ac4-ec5a-25a7e9ae1fc5"
      },
      "source": [
        "begin = time.time()\n",
        "epochs = 200\n",
        "for i in range(10):\n",
        "    print(i)\n",
        "    loader_1 = dataloaders_1[i]\n",
        "    loader_2 = dataloaders_2[i]\n",
        "    DM = DMNIST()\n",
        "    DU = DUSPS()\n",
        "    GMU = GMNISTUSPS()\n",
        "    GUM = GUSPSMNIST()\n",
        "    \n",
        "    lambda_ = 0.0002\n",
        "  \n",
        "    G_params = list(GMU.parameters()) + list(GUM.parameters())\n",
        "    D_params = list(DM.parameters()) + list(DU.parameters())\n",
        "        \n",
        "    G_optimizer = optim.Adam(G_params, lambda_)\n",
        "\n",
        "    D_optimizer = optim.Adam(D_params, lambda_)\n",
        "\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"gpu\")\n",
        "        DM.cuda()\n",
        "        DU.cuda()\n",
        "        GMU.cuda()\n",
        "        GUM.cuda()\n",
        "    train(loader_2,loader_1)\n",
        "    #enregistrement des models\n",
        "    torch.save(DM.state_dict(), \"./model/D_mnist_{}.pth\".format(i))\n",
        "    torch.save(DU.state_dict(),  \"./model/D_usps_{}.pth\".format(i))\n",
        "    torch.save(GMU.state_dict(),  \"./model/G_mnisttousps_{}.pth\".format(i))\n",
        "    torch.save(GUM.state_dict(),  \"./model/G_uspstomnist_{}.pth\".format(i))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "gpu\n",
            "step 500 on 3800, real loss: 0.13353444635868073 , fake loss: 0.08982214331626892 ,  Gen loss: 3.6244137287139893\n",
            "lambda = 0.0002\n",
            "total time: 27.390979051589966\n",
            "step 1000 on 3800, real loss: 0.1040114015340805 , fake loss: 0.09132496267557144 ,  Gen loss: 3.173264265060425\n",
            "lambda = 0.0002\n",
            "total time: 51.142638206481934\n",
            "step 1500 on 3800, real loss: 0.08100522309541702 , fake loss: 0.03569338470697403 ,  Gen loss: 2.1628377437591553\n",
            "lambda = 0.0002\n",
            "total time: 74.74612951278687\n",
            "step 2000 on 3800, real loss: 0.055622201412916183 , fake loss: 0.09475578367710114 ,  Gen loss: 2.995931386947632\n",
            "lambda = 0.00019400000000000003\n",
            "total time: 98.6977527141571\n",
            "step 2500 on 3800, real loss: 0.021887894719839096 , fake loss: 0.05622156336903572 ,  Gen loss: 2.5792956352233887\n",
            "lambda = 0.00014200000000000017\n",
            "total time: 122.5577392578125\n",
            "step 3000 on 3800, real loss: 0.07223937660455704 , fake loss: 0.08479520678520203 ,  Gen loss: 2.441288948059082\n",
            "lambda = 9.000000000000032e-05\n",
            "total time: 146.40523433685303\n",
            "step 3500 on 3800, real loss: 0.04454275220632553 , fake loss: 0.055237773805856705 ,  Gen loss: 2.6457250118255615\n",
            "lambda = 3.600000000000038e-05\n",
            "total time: 170.57139611244202\n",
            "1\n",
            "gpu\n",
            "step 500 on 3200, real loss: 0.07880707085132599 , fake loss: 0.06120767816901207 ,  Gen loss: 2.0743918418884277\n",
            "lambda = 0.0002\n",
            "total time: 209.76751375198364\n",
            "step 1000 on 3200, real loss: 0.06846681982278824 , fake loss: 0.04760577529668808 ,  Gen loss: 2.0787081718444824\n",
            "lambda = 0.0002\n",
            "total time: 233.5434136390686\n",
            "step 1500 on 3200, real loss: 0.06547071039676666 , fake loss: 0.07928413152694702 ,  Gen loss: 1.74648118019104\n",
            "lambda = 0.0002\n",
            "total time: 257.4747016429901\n",
            "step 2000 on 3200, real loss: 0.06704219430685043 , fake loss: 0.4552774429321289 ,  Gen loss: 1.8136647939682007\n",
            "lambda = 0.00015400000000000014\n",
            "total time: 281.3143825531006\n",
            "step 2500 on 3200, real loss: 0.11685152351856232 , fake loss: 0.07332845032215118 ,  Gen loss: 1.8616349697113037\n",
            "lambda = 9.200000000000031e-05\n",
            "total time: 304.96829628944397\n",
            "step 3000 on 3200, real loss: 0.09214558452367783 , fake loss: 0.09630659967660904 ,  Gen loss: 1.6100256443023682\n",
            "lambda = 3.0000000000000377e-05\n",
            "total time: 328.83794593811035\n",
            "2\n",
            "gpu\n",
            "step 500 on 2400, real loss: 0.1548503041267395 , fake loss: 0.10580489784479141 ,  Gen loss: 5.113645553588867\n",
            "lambda = 0.0002\n",
            "total time: 363.0474498271942\n",
            "step 1000 on 2400, real loss: 0.08270525187253952 , fake loss: 0.10306788980960846 ,  Gen loss: 4.102932453155518\n",
            "lambda = 0.0002\n",
            "total time: 386.8069965839386\n",
            "step 1500 on 2400, real loss: 0.03299965336918831 , fake loss: 0.2535795569419861 ,  Gen loss: 3.4304027557373047\n",
            "lambda = 0.00015400000000000014\n",
            "total time: 410.99230456352234\n",
            "step 2000 on 2400, real loss: 0.08543048799037933 , fake loss: 0.0948033481836319 ,  Gen loss: 3.36541748046875\n",
            "lambda = 7.200000000000037e-05\n",
            "total time: 434.6775677204132\n",
            "3\n",
            "gpu\n",
            "step 500 on 2200, real loss: 0.2092566341161728 , fake loss: 0.10011199116706848 ,  Gen loss: 5.502565383911133\n",
            "lambda = 0.0002\n",
            "total time: 478.1264259815216\n",
            "step 1000 on 2200, real loss: 0.14071020483970642 , fake loss: 0.08990927785634995 ,  Gen loss: 1.8377745151519775\n",
            "lambda = 0.0002\n",
            "total time: 501.9458518028259\n",
            "step 1500 on 2200, real loss: 0.12676624953746796 , fake loss: 0.07025666534900665 ,  Gen loss: 3.498274326324463\n",
            "lambda = 0.0001320000000000002\n",
            "total time: 525.9005665779114\n",
            "step 2000 on 2200, real loss: 0.07616551220417023 , fake loss: 0.05360264703631401 ,  Gen loss: 3.482510566711426\n",
            "lambda = 4.2000000000000384e-05\n",
            "total time: 549.7872266769409\n",
            "4\n",
            "gpu\n",
            "step 500 on 2200, real loss: 0.11558350175619125 , fake loss: 0.15006881952285767 ,  Gen loss: 4.272976398468018\n",
            "lambda = 0.0002\n",
            "total time: 583.5831160545349\n",
            "step 1000 on 2200, real loss: 0.06475462019443512 , fake loss: 0.10545192658901215 ,  Gen loss: 1.6771247386932373\n",
            "lambda = 0.0002\n",
            "total time: 607.2585506439209\n",
            "step 1500 on 2200, real loss: 0.10273430496454239 , fake loss: 0.10546562075614929 ,  Gen loss: 2.9187002182006836\n",
            "lambda = 0.0001320000000000002\n",
            "total time: 631.057195186615\n",
            "step 2000 on 2200, real loss: 0.029507344588637352 , fake loss: 0.08650026470422745 ,  Gen loss: 3.0286505222320557\n",
            "lambda = 4.2000000000000384e-05\n",
            "total time: 655.2360191345215\n",
            "5\n",
            "gpu\n",
            "step 500 on 1800, real loss: 0.0732976645231247 , fake loss: 0.06790857762098312 ,  Gen loss: 4.984846591949463\n",
            "lambda = 0.0002\n",
            "total time: 688.8505320549011\n",
            "step 1000 on 1800, real loss: 0.037064824253320694 , fake loss: 0.04643269255757332 ,  Gen loss: 3.9967377185821533\n",
            "lambda = 0.00018200000000000006\n",
            "total time: 712.4807567596436\n",
            "step 1500 on 1800, real loss: 0.07427085936069489 , fake loss: 0.03298773244023323 ,  Gen loss: 3.694762706756592\n",
            "lambda = 7.200000000000037e-05\n",
            "total time: 736.444522857666\n",
            "6\n",
            "gpu\n",
            "step 500 on 2200, real loss: 0.19823628664016724 , fake loss: 0.11125285923480988 ,  Gen loss: 3.9412970542907715\n",
            "lambda = 0.0002\n",
            "total time: 776.9094803333282\n",
            "step 1000 on 2200, real loss: 0.07948294281959534 , fake loss: 0.14870455861091614 ,  Gen loss: 1.7362704277038574\n",
            "lambda = 0.0002\n",
            "total time: 801.8621113300323\n",
            "step 1500 on 2200, real loss: 0.13361066579818726 , fake loss: 0.05931608006358147 ,  Gen loss: 2.8404555320739746\n",
            "lambda = 0.0001320000000000002\n",
            "total time: 826.1494405269623\n",
            "step 2000 on 2200, real loss: 0.10028041154146194 , fake loss: 0.0865192860364914 ,  Gen loss: 2.74538516998291\n",
            "lambda = 4.2000000000000384e-05\n",
            "total time: 850.3860576152802\n",
            "7\n",
            "gpu\n",
            "step 500 on 2200, real loss: 0.1006142795085907 , fake loss: 0.05125334858894348 ,  Gen loss: 4.905646324157715\n",
            "lambda = 0.0002\n",
            "total time: 884.7064707279205\n",
            "step 1000 on 2200, real loss: 0.14046159386634827 , fake loss: 0.04593034088611603 ,  Gen loss: 1.2684117555618286\n",
            "lambda = 0.0002\n",
            "total time: 908.6944184303284\n",
            "step 1500 on 2200, real loss: 0.09164386987686157 , fake loss: 0.07226540893316269 ,  Gen loss: 3.314880847930908\n",
            "lambda = 0.0001320000000000002\n",
            "total time: 932.6351499557495\n",
            "step 2000 on 2200, real loss: 0.05258670821785927 , fake loss: 0.030608586966991425 ,  Gen loss: 3.0707874298095703\n",
            "lambda = 4.2000000000000384e-05\n",
            "total time: 956.7122755050659\n",
            "8\n",
            "gpu\n",
            "step 500 on 1800, real loss: 0.1626920849084854 , fake loss: 0.09093110263347626 ,  Gen loss: 5.025827407836914\n",
            "lambda = 0.0002\n",
            "total time: 990.8662009239197\n",
            "step 1000 on 1800, real loss: 0.09971533715724945 , fake loss: 0.15167546272277832 ,  Gen loss: 4.118803977966309\n",
            "lambda = 0.00018200000000000006\n",
            "total time: 1014.9082200527191\n",
            "step 1500 on 1800, real loss: 0.06311197578907013 , fake loss: 0.07077020406723022 ,  Gen loss: 3.387737274169922\n",
            "lambda = 7.200000000000037e-05\n",
            "total time: 1039.304790019989\n",
            "9\n",
            "gpu\n",
            "step 500 on 2200, real loss: 0.20906445384025574 , fake loss: 0.167676642537117 ,  Gen loss: 3.571497678756714\n",
            "lambda = 0.0002\n",
            "total time: 1078.172788143158\n",
            "step 1000 on 2200, real loss: 0.14353309571743011 , fake loss: 0.12182622402906418 ,  Gen loss: 1.0566020011901855\n",
            "lambda = 0.0002\n",
            "total time: 1102.1145603656769\n",
            "step 1500 on 2200, real loss: 0.17896702885627747 , fake loss: 0.09372170269489288 ,  Gen loss: 2.6785659790039062\n",
            "lambda = 0.0001320000000000002\n",
            "total time: 1126.2038753032684\n",
            "step 2000 on 2200, real loss: 0.15644831955432892 , fake loss: 0.10833486914634705 ,  Gen loss: 2.3646323680877686\n",
            "lambda = 4.2000000000000384e-05\n",
            "total time: 1150.196785211563\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnYRrm8MQPcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "d7b35ba2-83d5-410e-f534-924e566297d8"
      },
      "source": [
        "#création d'un fichier zip à télécharger dans colab\n",
        "!zip -r /content/model.zip /content/model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/model/ (stored 0%)\n",
            "  adding: content/model/D_mnist_4.pth (deflated 8%)\n",
            "  adding: content/model/D_mnist_5.pth (deflated 8%)\n",
            "  adding: content/model/D_usps_3.pth (deflated 9%)\n",
            "  adding: content/model/D_mnist_8.pth (deflated 8%)\n",
            "  adding: content/model/G_uspstomnist_0.pth (deflated 9%)\n",
            "  adding: content/model/D_usps_7.pth (deflated 9%)\n",
            "  adding: content/model/G_uspstomnist_5.pth (deflated 9%)\n",
            "  adding: content/model/G_uspstomnist_1.pth (deflated 9%)\n",
            "  adding: content/model/G_uspstomnist_2.pth (deflated 9%)\n",
            "  adding: content/model/G_mnisttousps_3.pth (deflated 9%)\n",
            "  adding: content/model/D_usps_4.pth (deflated 9%)\n",
            "  adding: content/model/D_mnist_6.pth (deflated 8%)\n",
            "  adding: content/model/G_uspstomnist_6.pth (deflated 9%)\n",
            "  adding: content/model/D_mnist_9.pth (deflated 8%)\n",
            "  adding: content/model/D_usps_5.pth (deflated 9%)\n",
            "  adding: content/model/G_uspstomnist_7.pth (deflated 9%)\n",
            "  adding: content/model/G_uspstomnist_3.pth (deflated 9%)\n",
            "  adding: content/model/G_mnisttousps_6.pth (deflated 9%)\n",
            "  adding: content/model/D_usps_2.pth (deflated 9%)\n",
            "  adding: content/model/D_mnist_7.pth (deflated 8%)\n",
            "  adding: content/model/D_usps_0.pth (deflated 9%)\n",
            "  adding: content/model/G_mnisttousps_1.pth (deflated 9%)\n",
            "  adding: content/model/D_mnist_3.pth (deflated 8%)\n",
            "  adding: content/model/D_usps_8.pth (deflated 9%)\n",
            "  adding: content/model/D_mnist_1.pth (deflated 8%)\n",
            "  adding: content/model/D_usps_6.pth (deflated 9%)\n",
            "  adding: content/model/G_mnisttousps_8.pth (deflated 9%)\n",
            "  adding: content/model/G_uspstomnist_9.pth (deflated 9%)\n",
            "  adding: content/model/G_mnisttousps_4.pth (deflated 9%)\n",
            "  adding: content/model/G_mnisttousps_9.pth (deflated 9%)\n",
            "  adding: content/model/D_mnist_2.pth (deflated 8%)\n",
            "  adding: content/model/G_uspstomnist_8.pth (deflated 9%)\n",
            "  adding: content/model/G_mnisttousps_2.pth (deflated 9%)\n",
            "  adding: content/model/G_mnisttousps_7.pth (deflated 9%)\n",
            "  adding: content/model/D_usps_9.pth (deflated 9%)\n",
            "  adding: content/model/G_mnisttousps_0.pth (deflated 9%)\n",
            "  adding: content/model/G_uspstomnist_4.pth (deflated 9%)\n",
            "  adding: content/model/D_usps_1.pth (deflated 9%)\n",
            "  adding: content/model/D_mnist_0.pth (deflated 8%)\n",
            "  adding: content/model/G_mnisttousps_5.pth (deflated 9%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6Ezj2jkFKCu"
      },
      "source": [
        "#téléchargement du fichier zip précédent\n",
        "from google.colab import files\n",
        "files.download(\"/content/model.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDfgRp8qcBk_"
      },
      "source": [
        "#exemple pour le chiffre 9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJid6jTJcBlD",
        "outputId": "b62d5d98-e2ba-4350-bb79-0659a5a33045"
      },
      "source": [
        "GMU = GMNISTUSPS()\n",
        "GMU.load_state_dict(torch.load(\"./model/G_mnisttousps_9.pth\"))\n",
        "\n",
        "GUM = GUSPSMNIST()\n",
        "GUM.load_state_dict(torch.load(\"./model/G_uspstomnist_9.pth\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd0EdjWhcBlG"
      },
      "source": [
        "X_test, y_test = loadlocal_mnist(\n",
        "        images_path='./MNIST_test_im', \n",
        "        labels_path='./MNIST_test_label')\n",
        "X_test = X_test/254\n",
        "with h5py.File(\"./usps.h5\", 'r') as hf:\n",
        "        test = hf.get('test')\n",
        "        X_te = test.get('data')[:]\n",
        "        y_te = test.get('target')[:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t9yM4PrcBlJ"
      },
      "source": [
        "x = np.expand_dims(X_test.reshape(10000,28,28), 1)\n",
        "tensor_x_1 = torch.from_numpy(x.astype(\"float32\")) # transform to torch tensor\n",
        "tensor_y_1 = torch.from_numpy(y_test.astype(\"float32\"))\n",
        "tensor_x_2 = torch.from_numpy(X_te.reshape(2007,1,16,16).astype(\"float32\"))\n",
        "tensor_y_2 = torch.from_numpy(y_te.astype(\"float32\"))\n",
        "my_dataset_1 = TensorDataset(tensor_x_1,tensor_y_1)# create your datset\n",
        "my_dataset_2 = TensorDataset(tensor_x_2,tensor_y_2)\n",
        "class_inds_1 = [torch.where(my_dataset_1.tensors[1] == i)[0]\n",
        "              for i in range(10)]\n",
        "class_inds_2 = [torch.where(my_dataset_2.tensors[1] == i)[0]\n",
        "              for i in range(10)]\n",
        "dataloaders_1 = [\n",
        "    DataLoader(\n",
        "        dataset=Subset(my_dataset_1, class_inds_1[i]),\n",
        "        batch_size=64,\n",
        "        shuffle=True,\n",
        "        drop_last=False)\n",
        "    for i in range(10)]\n",
        "\n",
        "dataloaders_2 = [\n",
        "    DataLoader(\n",
        "        dataset=Subset(my_dataset_2, class_inds_2[i]),\n",
        "        batch_size=64,\n",
        "        shuffle=True,\n",
        "        drop_last=False)\n",
        "    for i in range(10)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqzEpSkOcBlM"
      },
      "source": [
        "loader_1 = dataloaders_1[9]\n",
        "loader_2 = dataloaders_2[9]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJqIsMQXEYk-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "b3a72b17-1e32-4fd1-cf05-32f1dbc0369a"
      },
      "source": [
        "#traduction de MNIST à USPS\n",
        "for e in iter(loader_1):\n",
        "    plt.imshow(GMU(e[0].cuda())[0][0].detach().numpy().reshape(16,16))\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30_0y6fYvoBa",
        "outputId": "d0f0528a-3652-4cc8-c41f-7b3bc31fd233"
      },
      "source": [
        "#Traduction de USPS à MNIST\n",
        "for e in iter(loader_2):\n",
        "    plt.imshow(GUM(e[0].cuda())[0][0].cpu().detach().numpy().reshape(28,28))\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PuH3_xSNp4I",
        "outputId": "ffe3a39e-9f42-40ec-e8c0-b0228aac5d55"
      },
      "source": [
        "#cycle MNIST --- > USPS --- > MNIST\n",
        "for e in iter(loader_1):\n",
        "    plt.imshow(GUM(GMU(e[0].cuda()))[0][0].cpu().detach().numpy().reshape(28,28))\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYXjciBoV7yV",
        "outputId": "bbafbe10-8bf9-4e93-f3aa-0e362da94e09"
      },
      "source": [
        "#cycle USPS --- > MNIST --- > USPS\n",
        "for e in iter(loader_2):\n",
        "    plt.imshow(GMU(GUM(e[0]))[0][0].cpu().detach().numpy().reshape(16,16))\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}